{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keystroke.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yki9rPbfuxRl"
      },
      "source": [
        "##### Import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0sS30RhusN5",
        "outputId": "047ce30c-cb4c-471a-fa26-cd64565e7d68"
      },
      "source": [
        "# when in google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pip install scikeras --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmd7V45Vu3S0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from keras.utils.np_utils import to_categorical \n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization,\\\n",
        "Flatten, LSTM\n",
        "# from scikeras.wrappers import KerasClassifier\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import load_model\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "NUM_FEATURES = 31\n",
        "TIMESTEPS = 1\n",
        "DATASET_LINK = \"https://raw.githubusercontent.com/ehandywhyy/ict3204-security-analytics/main/dataset/overall.csv\"\n",
        "TEST_DATA_LINK = \"https://raw.githubusercontent.com/ehandywhyy/ict3204-security-analytics/main/dataset/overall_test.csv\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9LuaURiPqv3"
      },
      "source": [
        "##### Initialise Seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "066fT-NcPqVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "7a90fef2-8ea7-4d9e-f367-8c42ae867b4c"
      },
      "source": [
        "# random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# loading of dataset\n",
        "df = pd.read_csv(DATASET_LINK)\n",
        "\n",
        "# # Remove missing values IF AVAILABLE and print head\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>sessionIndex</th>\n",
              "      <th>rep</th>\n",
              "      <th>H.period</th>\n",
              "      <th>DD.period.t</th>\n",
              "      <th>UD.period.t</th>\n",
              "      <th>H.t</th>\n",
              "      <th>DD.t.i</th>\n",
              "      <th>UD.t.i</th>\n",
              "      <th>H.i</th>\n",
              "      <th>DD.i.e</th>\n",
              "      <th>UD.i.e</th>\n",
              "      <th>H.e</th>\n",
              "      <th>DD.e.five</th>\n",
              "      <th>UD.e.five</th>\n",
              "      <th>H.five</th>\n",
              "      <th>DD.five.Shift.r</th>\n",
              "      <th>UD.five.Shift.r</th>\n",
              "      <th>H.Shift.r</th>\n",
              "      <th>DD.Shift.r.o</th>\n",
              "      <th>UD.Shift.r.o</th>\n",
              "      <th>H.o</th>\n",
              "      <th>DD.o.a</th>\n",
              "      <th>UD.o.a</th>\n",
              "      <th>H.a</th>\n",
              "      <th>DD.a.n</th>\n",
              "      <th>UD.a.n</th>\n",
              "      <th>H.n</th>\n",
              "      <th>DD.n.l</th>\n",
              "      <th>UD.n.l</th>\n",
              "      <th>H.l</th>\n",
              "      <th>DD.l.Return</th>\n",
              "      <th>UD.l.Return</th>\n",
              "      <th>H.Return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.142176</td>\n",
              "      <td>0.156880</td>\n",
              "      <td>0.014704</td>\n",
              "      <td>0.127937</td>\n",
              "      <td>0.142299</td>\n",
              "      <td>0.014361</td>\n",
              "      <td>0.155919</td>\n",
              "      <td>0.116134</td>\n",
              "      <td>-0.039784</td>\n",
              "      <td>0.124244</td>\n",
              "      <td>0.276458</td>\n",
              "      <td>0.152215</td>\n",
              "      <td>0.137177</td>\n",
              "      <td>0.641011</td>\n",
              "      <td>0.503834</td>\n",
              "      <td>0.125197</td>\n",
              "      <td>0.124527</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>0.122092</td>\n",
              "      <td>0.100097</td>\n",
              "      <td>-0.021995</td>\n",
              "      <td>0.128263</td>\n",
              "      <td>0.085967</td>\n",
              "      <td>-0.042296</td>\n",
              "      <td>0.120442</td>\n",
              "      <td>0.209372</td>\n",
              "      <td>0.088930</td>\n",
              "      <td>0.116911</td>\n",
              "      <td>0.165437</td>\n",
              "      <td>0.048526</td>\n",
              "      <td>0.160258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.141793</td>\n",
              "      <td>0.164635</td>\n",
              "      <td>0.022842</td>\n",
              "      <td>0.121625</td>\n",
              "      <td>0.152146</td>\n",
              "      <td>0.030520</td>\n",
              "      <td>0.137039</td>\n",
              "      <td>0.121543</td>\n",
              "      <td>-0.015496</td>\n",
              "      <td>0.104216</td>\n",
              "      <td>0.218603</td>\n",
              "      <td>0.114388</td>\n",
              "      <td>0.156909</td>\n",
              "      <td>0.346147</td>\n",
              "      <td>0.189238</td>\n",
              "      <td>0.138544</td>\n",
              "      <td>0.156244</td>\n",
              "      <td>0.017699</td>\n",
              "      <td>0.120454</td>\n",
              "      <td>0.088308</td>\n",
              "      <td>-0.032146</td>\n",
              "      <td>0.144490</td>\n",
              "      <td>0.082397</td>\n",
              "      <td>-0.062093</td>\n",
              "      <td>0.101188</td>\n",
              "      <td>0.126066</td>\n",
              "      <td>0.024878</td>\n",
              "      <td>0.098424</td>\n",
              "      <td>0.130661</td>\n",
              "      <td>0.032238</td>\n",
              "      <td>0.173819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.157152</td>\n",
              "      <td>0.147220</td>\n",
              "      <td>-0.009932</td>\n",
              "      <td>0.134796</td>\n",
              "      <td>0.145790</td>\n",
              "      <td>0.010994</td>\n",
              "      <td>0.124892</td>\n",
              "      <td>0.101461</td>\n",
              "      <td>-0.023431</td>\n",
              "      <td>0.112165</td>\n",
              "      <td>0.202102</td>\n",
              "      <td>0.089937</td>\n",
              "      <td>0.140860</td>\n",
              "      <td>0.274559</td>\n",
              "      <td>0.133699</td>\n",
              "      <td>0.142558</td>\n",
              "      <td>0.309424</td>\n",
              "      <td>0.166866</td>\n",
              "      <td>0.121442</td>\n",
              "      <td>0.101698</td>\n",
              "      <td>-0.019745</td>\n",
              "      <td>0.135452</td>\n",
              "      <td>0.082423</td>\n",
              "      <td>-0.053029</td>\n",
              "      <td>0.108598</td>\n",
              "      <td>0.155843</td>\n",
              "      <td>0.047244</td>\n",
              "      <td>0.118759</td>\n",
              "      <td>0.146550</td>\n",
              "      <td>0.027791</td>\n",
              "      <td>0.173512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.158673</td>\n",
              "      <td>0.142487</td>\n",
              "      <td>-0.016186</td>\n",
              "      <td>0.118908</td>\n",
              "      <td>0.159179</td>\n",
              "      <td>0.040271</td>\n",
              "      <td>0.133175</td>\n",
              "      <td>0.060895</td>\n",
              "      <td>-0.072279</td>\n",
              "      <td>0.106036</td>\n",
              "      <td>0.333517</td>\n",
              "      <td>0.227481</td>\n",
              "      <td>0.145889</td>\n",
              "      <td>0.287380</td>\n",
              "      <td>0.141491</td>\n",
              "      <td>0.125951</td>\n",
              "      <td>0.136230</td>\n",
              "      <td>0.010279</td>\n",
              "      <td>0.108067</td>\n",
              "      <td>0.114496</td>\n",
              "      <td>0.006429</td>\n",
              "      <td>0.114266</td>\n",
              "      <td>0.072556</td>\n",
              "      <td>-0.041711</td>\n",
              "      <td>0.101937</td>\n",
              "      <td>0.145692</td>\n",
              "      <td>0.043755</td>\n",
              "      <td>0.096300</td>\n",
              "      <td>0.122580</td>\n",
              "      <td>0.026280</td>\n",
              "      <td>0.190808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.166583</td>\n",
              "      <td>0.157102</td>\n",
              "      <td>-0.009480</td>\n",
              "      <td>0.115094</td>\n",
              "      <td>0.141103</td>\n",
              "      <td>0.026009</td>\n",
              "      <td>0.135121</td>\n",
              "      <td>0.082097</td>\n",
              "      <td>-0.053024</td>\n",
              "      <td>0.128655</td>\n",
              "      <td>0.192888</td>\n",
              "      <td>0.064234</td>\n",
              "      <td>0.165007</td>\n",
              "      <td>0.286537</td>\n",
              "      <td>0.121530</td>\n",
              "      <td>0.126328</td>\n",
              "      <td>0.119997</td>\n",
              "      <td>-0.006331</td>\n",
              "      <td>0.113122</td>\n",
              "      <td>0.082637</td>\n",
              "      <td>-0.030484</td>\n",
              "      <td>0.125474</td>\n",
              "      <td>0.089247</td>\n",
              "      <td>-0.036227</td>\n",
              "      <td>0.114211</td>\n",
              "      <td>0.149136</td>\n",
              "      <td>0.034925</td>\n",
              "      <td>0.121197</td>\n",
              "      <td>0.230113</td>\n",
              "      <td>0.108917</td>\n",
              "      <td>0.143299</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subject  sessionIndex  rep  ...  DD.l.Return  UD.l.Return  H.Return\n",
              "0    Andy             1    1  ...     0.165437     0.048526  0.160258\n",
              "1    Andy             1    2  ...     0.130661     0.032238  0.173819\n",
              "2    Andy             1    3  ...     0.146550     0.027791  0.173512\n",
              "3    Andy             1    4  ...     0.122580     0.026280  0.190808\n",
              "4    Andy             1    5  ...     0.230113     0.108917  0.143299\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDsF71P6lL4A"
      },
      "source": [
        "##### Divide dataset into X and Y\n",
        "##### Normalise features within range 0 (minimum) and 1 (maximum)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d28icPmWaXsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a34b98c-4656-42e0-f341-886d08adfacd"
      },
      "source": [
        "dataset = df.values\n",
        "\n",
        "# divide data into features X and target (Classes) Y\n",
        "X = dataset[:,3:].astype(float)\n",
        "Y = dataset[:,0]\n",
        "\n",
        "# # check for class imbalance\n",
        "print(df.groupby(Y).size())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Andy       100\n",
            "Azfar      100\n",
            "Chris      100\n",
            "Qikai      100\n",
            "Safaraz    100\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPl7j2SfHWLI",
        "outputId": "6be3a2c7-eee3-49e6-8cb6-2a1e4606c3e5"
      },
      "source": [
        "# convert target Y to one hot encoded Y for model\n",
        "Y = Y.reshape(-1, 1)\n",
        "encoder = OneHotEncoder().fit(Y)\n",
        "\n",
        "# get all the encoded class\n",
        "print(encoder.get_feature_names_out())\n",
        "\n",
        "# print X and Y shape\n",
        "print(\"X dataset shape: \" + str(X.shape))\n",
        "print(\"Y dataset shape: \" + str(Y.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['x0_Andy' 'x0_Azfar' 'x0_Chris' 'x0_Qikai' 'x0_Safaraz']\n",
            "X dataset shape: (500, 31)\n",
            "Y dataset shape: (500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpOqfe88l6kY"
      },
      "source": [
        "##### Preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_WWovqJnT7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309db901-b4ea-4328-cb29-8acef1f6e4b8"
      },
      "source": [
        "# split dataset into train and test of 0.8/0.2 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=seed)\n",
        "\n",
        "# normalisation to 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# reshaping the dataset to include LSTM\n",
        "X_train = np.asarray(X_train, dtype=np.float32)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], TIMESTEPS, X_train.shape[1]))\n",
        "X_test = np.asarray(X_test, dtype=np.float32)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], TIMESTEPS, X_test.shape[1]))\n",
        "\n",
        "# converting y data to encoding\n",
        "y_train = encoder.transform(y_train).toarray()\n",
        "y_test = encoder.transform(y_test).toarray()\n",
        "\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(\"X train shape: \" + str(X_train.shape))\n",
        "print(\"Y train shape: \" + str(y_train.shape))\n",
        "print(\"X test shape: \" + str(X_test.shape))\n",
        "print(\"Y test shape: \" + str(y_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train shape: (400, 1, 31)\n",
            "Y train shape: (400, 5)\n",
            "X test shape: (100, 1, 31)\n",
            "Y test shape: (100, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN14qb9GmR6_"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ZgrDxXKh05"
      },
      "source": [
        "def create_model():\n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=128, return_sequences=True, \n",
        "                 input_shape=(TIMESTEPS,NUM_FEATURES)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LSTM(units=128, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LSTM(units=64, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    # Softmax for multi-class classification\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQOFDctVmVjf"
      },
      "source": [
        "##### Wrap Model in KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sef5kxx5VZqt"
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model, epochs=100, \n",
        "                            batch_size=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LouGE3MmbO1"
      },
      "source": [
        "### Perform KFold Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WDOQfPzV9-N"
      },
      "source": [
        "num_folds = 10\n",
        "kfold = KFold(n_splits=num_folds, \n",
        "              shuffle=True,\n",
        "              random_state=seed)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOSGgRxamf1f"
      },
      "source": [
        "##### Get Accuracy from KFold Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1KNEriNgU5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fecd33d-069a-47e3-bd5d-2b8768037b90"
      },
      "source": [
        "results = cross_val_score(model, X_train, y_train, \n",
        "                          cv=kfold, error_score=\"raise\", verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 6s 10ms/step - loss: 1.0015 - accuracy: 0.6139\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3985 - accuracy: 0.8389\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.3657 - accuracy: 0.8667\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2785 - accuracy: 0.8917\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.3091 - accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2587 - accuracy: 0.8944\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.3343 - accuracy: 0.8750\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2800 - accuracy: 0.9111\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.3925 - accuracy: 0.8583\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2499 - accuracy: 0.9250\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2629 - accuracy: 0.9139\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1855 - accuracy: 0.9333\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2880 - accuracy: 0.9000\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2274 - accuracy: 0.9139\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2180 - accuracy: 0.9389\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.3097 - accuracy: 0.9139\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1755 - accuracy: 0.9472\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2129 - accuracy: 0.9361\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1699 - accuracy: 0.9500\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1934 - accuracy: 0.9250\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1730 - accuracy: 0.9278\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2043 - accuracy: 0.9444\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1309 - accuracy: 0.9583\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1744 - accuracy: 0.9361\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1745 - accuracy: 0.9417\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1442 - accuracy: 0.9556\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1797 - accuracy: 0.9278\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2266 - accuracy: 0.9222\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1509 - accuracy: 0.9500\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1393 - accuracy: 0.9444\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1733 - accuracy: 0.9417\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1921 - accuracy: 0.9278\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1381 - accuracy: 0.9528\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0929 - accuracy: 0.9722\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1669 - accuracy: 0.9528\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1978 - accuracy: 0.9389\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1605 - accuracy: 0.9528\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1589 - accuracy: 0.9500\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1151 - accuracy: 0.9667\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1858 - accuracy: 0.9500\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1273 - accuracy: 0.9611\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1172 - accuracy: 0.9611\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1153 - accuracy: 0.9556\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1195 - accuracy: 0.9556\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1282 - accuracy: 0.9639\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1293 - accuracy: 0.9611\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1263 - accuracy: 0.9639\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1588 - accuracy: 0.9417\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1107 - accuracy: 0.9639\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1834 - accuracy: 0.9361\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1531 - accuracy: 0.9639\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1368 - accuracy: 0.9500\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1721 - accuracy: 0.9417\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1339 - accuracy: 0.9500\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1295 - accuracy: 0.9583\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 0.9694\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1506 - accuracy: 0.9472\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9806\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1700 - accuracy: 0.9528\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1194 - accuracy: 0.9556\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1066 - accuracy: 0.9667\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1034 - accuracy: 0.9694\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1063 - accuracy: 0.9556\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1116 - accuracy: 0.9722\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1270 - accuracy: 0.9500\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1255 - accuracy: 0.9528\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1151 - accuracy: 0.9528\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1322 - accuracy: 0.9611\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1378 - accuracy: 0.9556\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1590 - accuracy: 0.9472\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0810 - accuracy: 0.9722\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0961 - accuracy: 0.9694\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0612 - accuracy: 0.9861\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1017 - accuracy: 0.9694\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1225 - accuracy: 0.9611\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0667 - accuracy: 0.9861\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9667\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1072 - accuracy: 0.9694\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1110 - accuracy: 0.9472\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0907 - accuracy: 0.9722\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1235 - accuracy: 0.9611\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0993 - accuracy: 0.9639\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0905 - accuracy: 0.9694\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0960 - accuracy: 0.9694\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0770 - accuracy: 0.9778\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0850 - accuracy: 0.9750\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.9722\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 0.9861\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0700 - accuracy: 0.9833\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1054 - accuracy: 0.9611\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1451 - accuracy: 0.9528\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1068 - accuracy: 0.9583\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9806\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0918 - accuracy: 0.9722\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0718 - accuracy: 0.9778\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1487 - accuracy: 0.9611\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9722\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0624 - accuracy: 0.9722\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0398 - accuracy: 0.9917\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 0.9806\n",
            "4/4 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 5s 9ms/step - loss: 0.9817 - accuracy: 0.5944\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.5080 - accuracy: 0.8417\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2865 - accuracy: 0.8972\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.3753 - accuracy: 0.8583\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2454 - accuracy: 0.9028\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2955 - accuracy: 0.8972\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2129 - accuracy: 0.9278\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.3336 - accuracy: 0.8694\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2730 - accuracy: 0.9028\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2030 - accuracy: 0.9250\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2727 - accuracy: 0.9028\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2982 - accuracy: 0.8861\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2413 - accuracy: 0.9250\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2378 - accuracy: 0.9167\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2504 - accuracy: 0.9250\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2184 - accuracy: 0.9333\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2796 - accuracy: 0.9056\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1383 - accuracy: 0.9528\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2323 - accuracy: 0.9222\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2114 - accuracy: 0.9222\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1702 - accuracy: 0.9472\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1396 - accuracy: 0.9472\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1740 - accuracy: 0.9222\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1879 - accuracy: 0.9417\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1693 - accuracy: 0.9417\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2906 - accuracy: 0.9000\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1781 - accuracy: 0.9472\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1682 - accuracy: 0.9417\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2217 - accuracy: 0.9167\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1801 - accuracy: 0.9306\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1347 - accuracy: 0.9500\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9417\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1487 - accuracy: 0.9361\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1602 - accuracy: 0.9500\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1546 - accuracy: 0.9500\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2111 - accuracy: 0.9306\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1267 - accuracy: 0.9583\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1612 - accuracy: 0.9444\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1462 - accuracy: 0.9611\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2052 - accuracy: 0.9194\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1089 - accuracy: 0.9750\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2055 - accuracy: 0.9167\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1296 - accuracy: 0.9556\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1132 - accuracy: 0.9639\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1127 - accuracy: 0.9639\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1552 - accuracy: 0.9472\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1364 - accuracy: 0.9556\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1659 - accuracy: 0.9417\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1128 - accuracy: 0.9611\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0987 - accuracy: 0.9750\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1490 - accuracy: 0.9528\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0956 - accuracy: 0.9694\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1217 - accuracy: 0.9556\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1368 - accuracy: 0.9417\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0801 - accuracy: 0.9750\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1582 - accuracy: 0.9528\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1247 - accuracy: 0.9639\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9556\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1317 - accuracy: 0.9500\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1138 - accuracy: 0.9528\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1137 - accuracy: 0.9556\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1301 - accuracy: 0.9556\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1020 - accuracy: 0.9611\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 0.9861\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.9694\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0962 - accuracy: 0.9722\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1031 - accuracy: 0.9694\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0969 - accuracy: 0.9583\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1122 - accuracy: 0.9694\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1125 - accuracy: 0.9611\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1299 - accuracy: 0.9750\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1395 - accuracy: 0.9639\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1004 - accuracy: 0.9694\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1165 - accuracy: 0.9750\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1409 - accuracy: 0.9528\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9694\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0851 - accuracy: 0.9750\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1079 - accuracy: 0.9639\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1395 - accuracy: 0.9528\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1194 - accuracy: 0.9611\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1175 - accuracy: 0.9500\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1489 - accuracy: 0.9528\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1148 - accuracy: 0.9778\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0968 - accuracy: 0.9694\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0776 - accuracy: 0.9667\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1059 - accuracy: 0.9611\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1146 - accuracy: 0.9583\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9639\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1456 - accuracy: 0.9500\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9750\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9694\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0810 - accuracy: 0.9722\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1083 - accuracy: 0.9500\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1331 - accuracy: 0.9556\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1058 - accuracy: 0.9667\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1147 - accuracy: 0.9500\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0847 - accuracy: 0.9722\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9861\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0682 - accuracy: 0.9750\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0572 - accuracy: 0.9806\n",
            "4/4 [==============================] - 1s 7ms/step - loss: 0.0575 - accuracy: 0.9750\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 6s 9ms/step - loss: 0.9964 - accuracy: 0.6167\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.4809 - accuracy: 0.8306\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.4178 - accuracy: 0.8611\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2432 - accuracy: 0.9194\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.3353 - accuracy: 0.8722\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.3721 - accuracy: 0.8778\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2645 - accuracy: 0.9056\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2124 - accuracy: 0.9250\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.4118 - accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2371 - accuracy: 0.9167\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2689 - accuracy: 0.9083\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2284 - accuracy: 0.9111\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2055 - accuracy: 0.9250\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2180 - accuracy: 0.9194\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2019 - accuracy: 0.9167\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1673 - accuracy: 0.9389\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2173 - accuracy: 0.9250\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1925 - accuracy: 0.9222\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2245 - accuracy: 0.9111\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1786 - accuracy: 0.9444\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2496 - accuracy: 0.9111\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1168 - accuracy: 0.9611\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1721 - accuracy: 0.9389\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2163 - accuracy: 0.9278\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1907 - accuracy: 0.9278\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9361\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1749 - accuracy: 0.9444\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1847 - accuracy: 0.9472\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1848 - accuracy: 0.9194\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1664 - accuracy: 0.9500\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1441 - accuracy: 0.9528\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1255 - accuracy: 0.9583\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1724 - accuracy: 0.9306\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1888 - accuracy: 0.9389\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1909 - accuracy: 0.9444\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1571 - accuracy: 0.9444\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1392 - accuracy: 0.9556\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2009 - accuracy: 0.9333\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1703 - accuracy: 0.9417\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1936 - accuracy: 0.9306\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1292 - accuracy: 0.9639\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1413 - accuracy: 0.9389\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9833\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2308 - accuracy: 0.9278\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2476 - accuracy: 0.9222\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1571 - accuracy: 0.9556\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1362 - accuracy: 0.9500\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1431 - accuracy: 0.9500\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1004 - accuracy: 0.9667\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1823 - accuracy: 0.9389\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0915 - accuracy: 0.9694\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1224 - accuracy: 0.9611\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0937 - accuracy: 0.9667\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0903 - accuracy: 0.9722\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1239 - accuracy: 0.9528\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1402 - accuracy: 0.9583\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0901 - accuracy: 0.9694\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9750\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0840 - accuracy: 0.9750\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0994 - accuracy: 0.9611\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1439 - accuracy: 0.9444\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1116 - accuracy: 0.9556\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1006 - accuracy: 0.9639\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.9833\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0913 - accuracy: 0.9667\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2138 - accuracy: 0.9361\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 0.9444\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1351 - accuracy: 0.9583\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0901 - accuracy: 0.9694\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1410 - accuracy: 0.9528\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1145 - accuracy: 0.9556\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0895 - accuracy: 0.9639\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0882 - accuracy: 0.9694\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0871 - accuracy: 0.9722\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0973 - accuracy: 0.9750\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1549 - accuracy: 0.9556\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1358 - accuracy: 0.9500\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1169 - accuracy: 0.9500\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0797 - accuracy: 0.9806\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.9667\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0815 - accuracy: 0.9750\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1117 - accuracy: 0.9694\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0858 - accuracy: 0.9722\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0969 - accuracy: 0.9583\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9694\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1009 - accuracy: 0.9778\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0625 - accuracy: 0.9833\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1157 - accuracy: 0.9583\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1204 - accuracy: 0.9556\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0562 - accuracy: 0.9889\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0685 - accuracy: 0.9778\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9722\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1237 - accuracy: 0.9667\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 0.9833\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1052 - accuracy: 0.9750\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1119 - accuracy: 0.9583\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0520 - accuracy: 0.9833\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0858 - accuracy: 0.9778\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 0.9667\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1858 - accuracy: 0.9500\n",
            "4/4 [==============================] - 1s 7ms/step - loss: 0.0780 - accuracy: 0.9750\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 6s 11ms/step - loss: 0.9445 - accuracy: 0.6444\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.4372 - accuracy: 0.8444\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3884 - accuracy: 0.8278\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.3773 - accuracy: 0.8750\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.3272 - accuracy: 0.8833\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2992 - accuracy: 0.8861\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3225 - accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2543 - accuracy: 0.9194\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.3277 - accuracy: 0.8778\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2609 - accuracy: 0.9056\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2824 - accuracy: 0.8972\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2265 - accuracy: 0.9167\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2498 - accuracy: 0.9111\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2323 - accuracy: 0.9306\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1964 - accuracy: 0.9333\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2951 - accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2186 - accuracy: 0.9222\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1931 - accuracy: 0.9389\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2162 - accuracy: 0.9167\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1854 - accuracy: 0.9389\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1781 - accuracy: 0.9278\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2278 - accuracy: 0.9333\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2579 - accuracy: 0.9167\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2104 - accuracy: 0.9306\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1971 - accuracy: 0.9389\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1997 - accuracy: 0.9250\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1660 - accuracy: 0.9444\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2149 - accuracy: 0.9250\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9556\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 0.9389\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9500\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1372 - accuracy: 0.9528\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1986 - accuracy: 0.9306\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1340 - accuracy: 0.9528\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1913 - accuracy: 0.9333\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1343 - accuracy: 0.9583\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1928 - accuracy: 0.9472\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1118 - accuracy: 0.9722\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1325 - accuracy: 0.9556\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0844 - accuracy: 0.9806\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0710 - accuracy: 0.9833\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9528\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1103 - accuracy: 0.9583\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2209 - accuracy: 0.9167\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1305 - accuracy: 0.9528\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1448 - accuracy: 0.9528\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0969 - accuracy: 0.9750\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0801 - accuracy: 0.9861\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1230 - accuracy: 0.9611\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1127 - accuracy: 0.9639\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0988 - accuracy: 0.9611\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1296 - accuracy: 0.9500\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1486 - accuracy: 0.9472\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1860 - accuracy: 0.9222\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1149 - accuracy: 0.9611\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1085 - accuracy: 0.9694\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1738 - accuracy: 0.9333\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1097 - accuracy: 0.9667\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0917 - accuracy: 0.9639\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0942 - accuracy: 0.9667\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1284 - accuracy: 0.9556\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1373 - accuracy: 0.9583\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1453 - accuracy: 0.9583\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1483 - accuracy: 0.9500\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1188 - accuracy: 0.9611\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1112 - accuracy: 0.9722\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1471 - accuracy: 0.9528\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0669 - accuracy: 0.9750\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9750\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1323 - accuracy: 0.9500\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1094 - accuracy: 0.9667\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1443 - accuracy: 0.9389\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0957 - accuracy: 0.9778\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0879 - accuracy: 0.9806\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1143 - accuracy: 0.9694\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0968 - accuracy: 0.9778\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1065 - accuracy: 0.9639\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0556 - accuracy: 0.9833\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1073 - accuracy: 0.9528\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1015 - accuracy: 0.9694\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1197 - accuracy: 0.9611\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1395 - accuracy: 0.9444\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1406 - accuracy: 0.9444\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0968 - accuracy: 0.9694\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1115 - accuracy: 0.9556\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1106 - accuracy: 0.9667\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0846 - accuracy: 0.9722\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.9694\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9806\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.9722\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0905 - accuracy: 0.9639\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0683 - accuracy: 0.9833\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1380 - accuracy: 0.9528\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0944 - accuracy: 0.9667\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0935 - accuracy: 0.9750\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.9611\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1288 - accuracy: 0.9583\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1047 - accuracy: 0.9639\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.9778\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 0.9778\n",
            "4/4 [==============================] - 1s 9ms/step - loss: 0.0440 - accuracy: 0.9750\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 5s 11ms/step - loss: 1.1417 - accuracy: 0.5583\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.5935 - accuracy: 0.7583\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.4386 - accuracy: 0.8444\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2943 - accuracy: 0.9028\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.4405 - accuracy: 0.8778\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3018 - accuracy: 0.8833\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2813 - accuracy: 0.8972\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1930 - accuracy: 0.9361\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3644 - accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3123 - accuracy: 0.8833\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2024 - accuracy: 0.9389\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2427 - accuracy: 0.9361\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1780 - accuracy: 0.9306\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2158 - accuracy: 0.9139\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1898 - accuracy: 0.9278\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1786 - accuracy: 0.9417\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1902 - accuracy: 0.9361\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2584 - accuracy: 0.9194\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2521 - accuracy: 0.9028\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2993 - accuracy: 0.8861\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1419 - accuracy: 0.9583\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2260 - accuracy: 0.9306\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2427 - accuracy: 0.9111\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1687 - accuracy: 0.9333\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1949 - accuracy: 0.9361\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1087 - accuracy: 0.9694\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1683 - accuracy: 0.9472\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2048 - accuracy: 0.9417\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2063 - accuracy: 0.9250\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 0.9528\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1710 - accuracy: 0.9472\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2442 - accuracy: 0.9139\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1812 - accuracy: 0.9500\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.9667\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2206 - accuracy: 0.9083\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1745 - accuracy: 0.9250\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1916 - accuracy: 0.9389\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1448 - accuracy: 0.9556\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1731 - accuracy: 0.9444\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.9583\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.9639\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1287 - accuracy: 0.9528\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9528\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0982 - accuracy: 0.9611\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1402 - accuracy: 0.9472\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1459 - accuracy: 0.9528\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1360 - accuracy: 0.9417\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0836 - accuracy: 0.9806\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1715 - accuracy: 0.9444\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1318 - accuracy: 0.9444\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1323 - accuracy: 0.9611\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1453 - accuracy: 0.9472\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1086 - accuracy: 0.9611\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1926 - accuracy: 0.9472\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1098 - accuracy: 0.9472\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1202 - accuracy: 0.9694\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1228 - accuracy: 0.9639\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1466 - accuracy: 0.9611\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1319 - accuracy: 0.9528\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1641 - accuracy: 0.9472\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1093 - accuracy: 0.9611\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1258 - accuracy: 0.9611\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1341 - accuracy: 0.9556\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1114 - accuracy: 0.9611\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1360 - accuracy: 0.9611\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2822 - accuracy: 0.9083\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1360 - accuracy: 0.9472\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1728 - accuracy: 0.9417\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1045 - accuracy: 0.9667\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1099 - accuracy: 0.9611\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0774 - accuracy: 0.9778\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0604 - accuracy: 0.9778\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1740 - accuracy: 0.9333\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0987 - accuracy: 0.9694\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1112 - accuracy: 0.9611\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1490 - accuracy: 0.9556\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0906 - accuracy: 0.9694\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0844 - accuracy: 0.9750\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1180 - accuracy: 0.9750\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1282 - accuracy: 0.9611\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1161 - accuracy: 0.9667\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0718 - accuracy: 0.9722\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0655 - accuracy: 0.9806\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1035 - accuracy: 0.9611\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0779 - accuracy: 0.9833\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1768 - accuracy: 0.9556\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1160 - accuracy: 0.9556\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1151 - accuracy: 0.9639\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.9778\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1140 - accuracy: 0.9611\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0971 - accuracy: 0.9694\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1359 - accuracy: 0.9500\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0614 - accuracy: 0.9722\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0553 - accuracy: 0.9861\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0892 - accuracy: 0.9639\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1705 - accuracy: 0.9389\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9778\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1709 - accuracy: 0.9444\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1076 - accuracy: 0.9472\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0977 - accuracy: 0.9722\n",
            "4/4 [==============================] - 1s 9ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 5s 11ms/step - loss: 1.0538 - accuracy: 0.5889\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.5803 - accuracy: 0.7806\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3853 - accuracy: 0.8472\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2644 - accuracy: 0.9056\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2149 - accuracy: 0.9278\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2782 - accuracy: 0.9000\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2755 - accuracy: 0.9000\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2642 - accuracy: 0.9056\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2390 - accuracy: 0.8972\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2400 - accuracy: 0.9222\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3023 - accuracy: 0.8917\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2799 - accuracy: 0.9028\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2039 - accuracy: 0.9222\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1903 - accuracy: 0.9417\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2103 - accuracy: 0.9250\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2473 - accuracy: 0.8944\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2286 - accuracy: 0.9111\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1686 - accuracy: 0.9417\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2122 - accuracy: 0.9389\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1964 - accuracy: 0.9250\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1613 - accuracy: 0.9417\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2436 - accuracy: 0.9167\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2104 - accuracy: 0.9333\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2215 - accuracy: 0.9361\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1420 - accuracy: 0.9611\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2572 - accuracy: 0.9306\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1583 - accuracy: 0.9556\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1981 - accuracy: 0.9333\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1221 - accuracy: 0.9667\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1578 - accuracy: 0.9472\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1658 - accuracy: 0.9500\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1416 - accuracy: 0.9528\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1944 - accuracy: 0.9333\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1509 - accuracy: 0.9583\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1308 - accuracy: 0.9528\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1240 - accuracy: 0.9444\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1597 - accuracy: 0.9556\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1710 - accuracy: 0.9361\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1748 - accuracy: 0.9472\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1827 - accuracy: 0.9361\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1285 - accuracy: 0.9583\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1475 - accuracy: 0.9472\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.9611\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1411 - accuracy: 0.9444\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1465 - accuracy: 0.9556\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1181 - accuracy: 0.9556\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1319 - accuracy: 0.9611\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1944 - accuracy: 0.9306\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2553 - accuracy: 0.9222\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1179 - accuracy: 0.9583\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1655 - accuracy: 0.9361\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1281 - accuracy: 0.9556\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1331 - accuracy: 0.9556\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1276 - accuracy: 0.9667\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1541 - accuracy: 0.9472\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1517 - accuracy: 0.9556\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0862 - accuracy: 0.9833\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1003 - accuracy: 0.9611\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0640 - accuracy: 0.9833\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1393 - accuracy: 0.9472\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1046 - accuracy: 0.9778\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1279 - accuracy: 0.9583\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0553 - accuracy: 0.9833\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1647 - accuracy: 0.9500\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1564 - accuracy: 0.9528\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1134 - accuracy: 0.9694\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1392 - accuracy: 0.9583\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.9444\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1414 - accuracy: 0.9583\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1462 - accuracy: 0.9528\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1377 - accuracy: 0.9667\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1004 - accuracy: 0.9750\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0712 - accuracy: 0.9750\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0927 - accuracy: 0.9722\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1280 - accuracy: 0.9694\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0707 - accuracy: 0.9861\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0746 - accuracy: 0.9750\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0748 - accuracy: 0.9778\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0750 - accuracy: 0.9750\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1212 - accuracy: 0.9750\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1116 - accuracy: 0.9556\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1317 - accuracy: 0.9472\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0657 - accuracy: 0.9889\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0861 - accuracy: 0.9694\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0793 - accuracy: 0.9750\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1293 - accuracy: 0.9528\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.9222\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1018 - accuracy: 0.9639\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0813 - accuracy: 0.9694\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0633 - accuracy: 0.9861\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0626 - accuracy: 0.9833\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 0.9806\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0896 - accuracy: 0.9778\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1253 - accuracy: 0.9556\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9611\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1068 - accuracy: 0.9639\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1180 - accuracy: 0.9583\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0646 - accuracy: 0.9806\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0837 - accuracy: 0.9667\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0702 - accuracy: 0.9778\n",
            "4/4 [==============================] - 1s 10ms/step - loss: 0.0979 - accuracy: 0.9500\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 5s 11ms/step - loss: 1.0844 - accuracy: 0.5528\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.4729 - accuracy: 0.8361\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3619 - accuracy: 0.8611\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3583 - accuracy: 0.8583\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.4127 - accuracy: 0.8444\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2572 - accuracy: 0.9194\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2572 - accuracy: 0.9111\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2281 - accuracy: 0.9167\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2367 - accuracy: 0.9167\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2665 - accuracy: 0.8972\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2873 - accuracy: 0.9000\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2013 - accuracy: 0.9306\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1738 - accuracy: 0.9306\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2347 - accuracy: 0.9222\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2992 - accuracy: 0.8944\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1988 - accuracy: 0.9306\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1467 - accuracy: 0.9583\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2322 - accuracy: 0.9083\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2031 - accuracy: 0.9389\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1758 - accuracy: 0.9583\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2315 - accuracy: 0.9361\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1747 - accuracy: 0.9444\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1757 - accuracy: 0.9444\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2120 - accuracy: 0.9139\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1887 - accuracy: 0.9333\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1729 - accuracy: 0.9500\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1704 - accuracy: 0.9417\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1560 - accuracy: 0.9472\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1666 - accuracy: 0.9417\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1326 - accuracy: 0.9528\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1433 - accuracy: 0.9389\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1982 - accuracy: 0.9278\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1136 - accuracy: 0.9722\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1535 - accuracy: 0.9444\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1139 - accuracy: 0.9583\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1368 - accuracy: 0.9472\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1521 - accuracy: 0.9500\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1111 - accuracy: 0.9694\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1682 - accuracy: 0.9583\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1129 - accuracy: 0.9639\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1466 - accuracy: 0.9500\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1097 - accuracy: 0.9528\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.9833\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1415 - accuracy: 0.9583\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1118 - accuracy: 0.9528\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1089 - accuracy: 0.9556\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1248 - accuracy: 0.9528\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.9639\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1035 - accuracy: 0.9611\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0893 - accuracy: 0.9667\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1550 - accuracy: 0.9389\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1650 - accuracy: 0.9528\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1764 - accuracy: 0.9528\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1030 - accuracy: 0.9611\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1366 - accuracy: 0.9528\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0779 - accuracy: 0.9806\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1029 - accuracy: 0.9750\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1126 - accuracy: 0.9556\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1370 - accuracy: 0.9472\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1081 - accuracy: 0.9611\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1004 - accuracy: 0.9583\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0852 - accuracy: 0.9722\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0922 - accuracy: 0.9778\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1037 - accuracy: 0.9583\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1528 - accuracy: 0.9500\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0916 - accuracy: 0.9694\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0725 - accuracy: 0.9750\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1224 - accuracy: 0.9528\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.9806\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1113 - accuracy: 0.9583\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1904 - accuracy: 0.9500\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1130 - accuracy: 0.9583\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1090 - accuracy: 0.9694\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1273 - accuracy: 0.9722\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0714 - accuracy: 0.9833\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1359 - accuracy: 0.9667\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1499 - accuracy: 0.9528\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1063 - accuracy: 0.9667\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0889 - accuracy: 0.9667\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9750\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0770 - accuracy: 0.9694\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0847 - accuracy: 0.9778\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0918 - accuracy: 0.9778\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 0.9778\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1428 - accuracy: 0.9500\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1089 - accuracy: 0.9611\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 0.9889\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1059 - accuracy: 0.9639\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1637 - accuracy: 0.9472\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0871 - accuracy: 0.9750\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0612 - accuracy: 0.9833\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0916 - accuracy: 0.9667\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1199 - accuracy: 0.9556\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0825 - accuracy: 0.9750\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1044 - accuracy: 0.9667\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0907 - accuracy: 0.9694\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0830 - accuracy: 0.9694\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0813 - accuracy: 0.9833\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0685 - accuracy: 0.9806\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0721 - accuracy: 0.9750\n",
            "4/4 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9500\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 6s 12ms/step - loss: 1.0551 - accuracy: 0.5806\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.5484 - accuracy: 0.8056\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.4295 - accuracy: 0.8472\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3041 - accuracy: 0.9028\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.3452 - accuracy: 0.8833\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2889 - accuracy: 0.8778\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2576 - accuracy: 0.9194\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2477 - accuracy: 0.9194\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1935 - accuracy: 0.9444\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.3357 - accuracy: 0.8889\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.9194\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2982 - accuracy: 0.8944\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2168 - accuracy: 0.9222\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.9528\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2926 - accuracy: 0.9028\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2698 - accuracy: 0.9000\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1885 - accuracy: 0.9417\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1503 - accuracy: 0.9500\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2059 - accuracy: 0.9222\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2554 - accuracy: 0.9083\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2116 - accuracy: 0.9222\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2122 - accuracy: 0.9333\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1312 - accuracy: 0.9556\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1426 - accuracy: 0.9583\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1712 - accuracy: 0.9444\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1620 - accuracy: 0.9472\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1198 - accuracy: 0.9667\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1807 - accuracy: 0.9278\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0990 - accuracy: 0.9639\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.9500\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1757 - accuracy: 0.9417\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1866 - accuracy: 0.9444\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2029 - accuracy: 0.9194\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1466 - accuracy: 0.9528\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1178 - accuracy: 0.9667\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1422 - accuracy: 0.9583\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1539 - accuracy: 0.9472\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1331 - accuracy: 0.9556\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1665 - accuracy: 0.9556\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1371 - accuracy: 0.9500\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1504 - accuracy: 0.9472\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1391 - accuracy: 0.9583\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.9694\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0992 - accuracy: 0.9722\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1246 - accuracy: 0.9500\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1498 - accuracy: 0.9417\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.9444\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1632 - accuracy: 0.9444\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1881 - accuracy: 0.9444\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1342 - accuracy: 0.9472\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1398 - accuracy: 0.9500\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1133 - accuracy: 0.9611\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0722 - accuracy: 0.9833\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1260 - accuracy: 0.9528\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.9528\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1578 - accuracy: 0.9472\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 0.9889\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9778\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.1213 - accuracy: 0.9556\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1028 - accuracy: 0.9667\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1324 - accuracy: 0.9583\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1104 - accuracy: 0.9611\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0819 - accuracy: 0.9750\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1055 - accuracy: 0.9667\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1364 - accuracy: 0.9417\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1075 - accuracy: 0.9611\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0852 - accuracy: 0.9722\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1104 - accuracy: 0.9639\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1414 - accuracy: 0.9417\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1124 - accuracy: 0.9528\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0645 - accuracy: 0.9833\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0820 - accuracy: 0.9722\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0790 - accuracy: 0.9722\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1308 - accuracy: 0.9500\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0911 - accuracy: 0.9778\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0632 - accuracy: 0.9778\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0949 - accuracy: 0.9694\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0972 - accuracy: 0.9750\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0885 - accuracy: 0.9611\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0857 - accuracy: 0.9750\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1776 - accuracy: 0.9472\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1273 - accuracy: 0.9722\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1120 - accuracy: 0.9694\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0729 - accuracy: 0.9778\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1799 - accuracy: 0.9306\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1222 - accuracy: 0.9556\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.9556\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0741 - accuracy: 0.9722\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0833 - accuracy: 0.9722\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1179 - accuracy: 0.9667\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0661 - accuracy: 0.9806\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1092 - accuracy: 0.9583\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1194 - accuracy: 0.9611\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1255 - accuracy: 0.9639\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0624 - accuracy: 0.9806\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1076 - accuracy: 0.9694\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0596 - accuracy: 0.9861\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0862 - accuracy: 0.9667\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9444\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0952 - accuracy: 0.9722\n",
            "4/4 [==============================] - 1s 10ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 6s 11ms/step - loss: 1.1360 - accuracy: 0.5389\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.4896 - accuracy: 0.8306\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.3323 - accuracy: 0.8806\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2785 - accuracy: 0.8972\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2999 - accuracy: 0.9028\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3223 - accuracy: 0.8806\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2184 - accuracy: 0.9278\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2727 - accuracy: 0.9194\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2671 - accuracy: 0.9111\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2618 - accuracy: 0.8944\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3273 - accuracy: 0.8667\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2930 - accuracy: 0.9056\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2313 - accuracy: 0.9306\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1841 - accuracy: 0.9306\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2588 - accuracy: 0.9083\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2378 - accuracy: 0.9083\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.3130 - accuracy: 0.9083\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2090 - accuracy: 0.9306\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1876 - accuracy: 0.9222\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1996 - accuracy: 0.9278\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.2118 - accuracy: 0.9389\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1288 - accuracy: 0.9583\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1450 - accuracy: 0.9583\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1680 - accuracy: 0.9417\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1742 - accuracy: 0.9278\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1461 - accuracy: 0.9500\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2173 - accuracy: 0.9361\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1334 - accuracy: 0.9417\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1849 - accuracy: 0.9278\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1572 - accuracy: 0.9417\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1557 - accuracy: 0.9611\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1388 - accuracy: 0.9556\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1800 - accuracy: 0.9361\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1642 - accuracy: 0.9472\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1226 - accuracy: 0.9639\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1432 - accuracy: 0.9556\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1125 - accuracy: 0.9639\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1263 - accuracy: 0.9583\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1719 - accuracy: 0.9389\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1160 - accuracy: 0.9500\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1549 - accuracy: 0.9472\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.9472\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1156 - accuracy: 0.9639\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1627 - accuracy: 0.9444\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1715 - accuracy: 0.9361\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.2115 - accuracy: 0.9417\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0947 - accuracy: 0.9639\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1218 - accuracy: 0.9667\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1015 - accuracy: 0.9639\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1106 - accuracy: 0.9694\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1774 - accuracy: 0.9472\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1338 - accuracy: 0.9528\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1687 - accuracy: 0.9528\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1557 - accuracy: 0.9472\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1704 - accuracy: 0.9389\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1102 - accuracy: 0.9611\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0983 - accuracy: 0.9667\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1001 - accuracy: 0.9722\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1473 - accuracy: 0.9611\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1444 - accuracy: 0.9639\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1098 - accuracy: 0.9611\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0891 - accuracy: 0.9722\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0992 - accuracy: 0.9750\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1354 - accuracy: 0.9583\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1634 - accuracy: 0.9389\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0923 - accuracy: 0.9750\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1561 - accuracy: 0.9500\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1230 - accuracy: 0.9694\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0839 - accuracy: 0.9722\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0626 - accuracy: 0.9833\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0919 - accuracy: 0.9611\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1072 - accuracy: 0.9667\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0830 - accuracy: 0.9722\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0991 - accuracy: 0.9722\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0782 - accuracy: 0.9639\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9611\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1268 - accuracy: 0.9556\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9750\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0759 - accuracy: 0.9722\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1039 - accuracy: 0.9639\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1366 - accuracy: 0.9583\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0671 - accuracy: 0.9722\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1225 - accuracy: 0.9667\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0715 - accuracy: 0.9833\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1210 - accuracy: 0.9722\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0927 - accuracy: 0.9778\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0772 - accuracy: 0.9722\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0908 - accuracy: 0.9667\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1726 - accuracy: 0.9389\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0813 - accuracy: 0.9806\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1913 - accuracy: 0.9528\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1146 - accuracy: 0.9639\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1115 - accuracy: 0.9694\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1174 - accuracy: 0.9667\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0972 - accuracy: 0.9694\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1192 - accuracy: 0.9583\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0701 - accuracy: 0.9806\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0725 - accuracy: 0.9778\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0726 - accuracy: 0.9778\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0391 - accuracy: 0.9917\n",
            "4/4 [==============================] - 1s 11ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 6s 12ms/step - loss: 0.9654 - accuracy: 0.6333\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.4789 - accuracy: 0.8222\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.3333 - accuracy: 0.8861\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2624 - accuracy: 0.8944\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2979 - accuracy: 0.8861\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2506 - accuracy: 0.9083\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2613 - accuracy: 0.9139\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2370 - accuracy: 0.9222\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2264 - accuracy: 0.9250\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2765 - accuracy: 0.9083\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2433 - accuracy: 0.9167\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1717 - accuracy: 0.9444\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2790 - accuracy: 0.9028\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2114 - accuracy: 0.9250\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2393 - accuracy: 0.9222\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2127 - accuracy: 0.9278\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1920 - accuracy: 0.9444\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1567 - accuracy: 0.9389\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2024 - accuracy: 0.9389\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1938 - accuracy: 0.9333\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1822 - accuracy: 0.9500\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.2041 - accuracy: 0.9306\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1819 - accuracy: 0.9417\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2146 - accuracy: 0.9167\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1908 - accuracy: 0.9222\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1577 - accuracy: 0.9444\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1753 - accuracy: 0.9389\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1432 - accuracy: 0.9611\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1910 - accuracy: 0.9361\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1713 - accuracy: 0.9306\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1894 - accuracy: 0.9389\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1802 - accuracy: 0.9444\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1884 - accuracy: 0.9306\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1524 - accuracy: 0.9528\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1070 - accuracy: 0.9667\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1505 - accuracy: 0.9389\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1769 - accuracy: 0.9500\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1912 - accuracy: 0.9417\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1400 - accuracy: 0.9444\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1285 - accuracy: 0.9583\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1343 - accuracy: 0.9639\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1240 - accuracy: 0.9611\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1899 - accuracy: 0.9361\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1362 - accuracy: 0.9389\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1182 - accuracy: 0.9556\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1278 - accuracy: 0.9472\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1107 - accuracy: 0.9556\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1823 - accuracy: 0.9472\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1636 - accuracy: 0.9417\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1224 - accuracy: 0.9556\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1191 - accuracy: 0.9611\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1457 - accuracy: 0.9611\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0875 - accuracy: 0.9667\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1289 - accuracy: 0.9583\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1173 - accuracy: 0.9583\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0918 - accuracy: 0.9722\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1111 - accuracy: 0.9722\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1036 - accuracy: 0.9667\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1154 - accuracy: 0.9528\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1210 - accuracy: 0.9639\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1184 - accuracy: 0.9556\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1596 - accuracy: 0.9444\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1435 - accuracy: 0.9528\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0942 - accuracy: 0.9750\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1014 - accuracy: 0.9722\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0702 - accuracy: 0.9694\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1081 - accuracy: 0.9500\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0969 - accuracy: 0.9583\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0954 - accuracy: 0.9722\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0715 - accuracy: 0.9694\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0790 - accuracy: 0.9806\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0496 - accuracy: 0.9861\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0644 - accuracy: 0.9750\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.9694\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1369 - accuracy: 0.9444\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.2297 - accuracy: 0.9278\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1096 - accuracy: 0.9694\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1062 - accuracy: 0.9722\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1330 - accuracy: 0.9472\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.9861\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1018 - accuracy: 0.9667\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0604 - accuracy: 0.9833\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1567 - accuracy: 0.9472\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0839 - accuracy: 0.9639\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1592 - accuracy: 0.9528\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0733 - accuracy: 0.9778\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1032 - accuracy: 0.9556\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1277 - accuracy: 0.9611\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0768 - accuracy: 0.9722\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0837 - accuracy: 0.9750\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0865 - accuracy: 0.9694\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9667\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0577 - accuracy: 0.9750\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1551 - accuracy: 0.9528\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0921 - accuracy: 0.9750\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.1048 - accuracy: 0.9694\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0649 - accuracy: 0.9833\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0822 - accuracy: 0.9667\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0417 - accuracy: 0.9917\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.0805 - accuracy: 0.9778\n",
            "4/4 [==============================] - 1s 9ms/step - loss: 0.1000 - accuracy: 0.9750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  8.6min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCIrlzyI0Bel"
      },
      "source": [
        "##### get validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ZEDl7Yz_51",
        "outputId": "5b0b9c77-7654-4c03-85ef-77d13e3b1660"
      },
      "source": [
        "print(\"Validation Accuracy of %.2f%% (with standard deviation of %.2f%%)\" % \n",
        "      (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy of 98.00% (with standard deviation of 1.87%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg36UBcsaNNo"
      },
      "source": [
        "##### fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NotcydKxlfxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559eb040-d217-4adc-8fc7-10f9161af191"
      },
      "source": [
        "# fit the model\n",
        "es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, patience=50,\n",
        "                   verbose=0)\n",
        "model.fit(X_train, y_train, callbacks=es)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 6s 9ms/step - loss: 1.0066 - accuracy: 0.6200\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.8225\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3953 - accuracy: 0.8400\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4279 - accuracy: 0.8550\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2890 - accuracy: 0.8950\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3048 - accuracy: 0.8875\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3295 - accuracy: 0.8850\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2987 - accuracy: 0.8950\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2642 - accuracy: 0.8975\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2623 - accuracy: 0.9125\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2267 - accuracy: 0.9225\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.8825\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2151 - accuracy: 0.9275\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1722 - accuracy: 0.9425\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2735 - accuracy: 0.9125\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2043 - accuracy: 0.9400\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1808 - accuracy: 0.9425\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2631 - accuracy: 0.9175\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1736 - accuracy: 0.9475\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2195 - accuracy: 0.9325\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1846 - accuracy: 0.9400\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2288 - accuracy: 0.9275\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1665 - accuracy: 0.9400\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1732 - accuracy: 0.9400\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1961 - accuracy: 0.9400\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1817 - accuracy: 0.9450\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2056 - accuracy: 0.9225\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1932 - accuracy: 0.9325\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1579 - accuracy: 0.9525\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1644 - accuracy: 0.9450\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1947 - accuracy: 0.9200\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1903 - accuracy: 0.9450\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9525\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1406 - accuracy: 0.9475\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2146 - accuracy: 0.9325\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1621 - accuracy: 0.9325\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.9575\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0859 - accuracy: 0.9650\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1410 - accuracy: 0.9600\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1451 - accuracy: 0.9475\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1520 - accuracy: 0.9450\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1162 - accuracy: 0.9650\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9525\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1595 - accuracy: 0.9525\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1703 - accuracy: 0.9475\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1226 - accuracy: 0.9550\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9500\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1070 - accuracy: 0.9600\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0917 - accuracy: 0.9700\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1393 - accuracy: 0.9625\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2118 - accuracy: 0.9300\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1870 - accuracy: 0.9400\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1223 - accuracy: 0.9750\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1480 - accuracy: 0.9600\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1333 - accuracy: 0.9600\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1312 - accuracy: 0.9600\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0996 - accuracy: 0.9625\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1089 - accuracy: 0.9725\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1135 - accuracy: 0.9575\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1349 - accuracy: 0.9650\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1670 - accuracy: 0.9500\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1285 - accuracy: 0.9625\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1748 - accuracy: 0.9375\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1537 - accuracy: 0.9600\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1205 - accuracy: 0.9500\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0971 - accuracy: 0.9750\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1303 - accuracy: 0.9500\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.9675\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0547 - accuracy: 0.9875\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9625\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1047 - accuracy: 0.9675\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1111 - accuracy: 0.9675\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0845 - accuracy: 0.9800\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1453 - accuracy: 0.9475\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0713 - accuracy: 0.9775\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1229 - accuracy: 0.9525\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0897 - accuracy: 0.9800\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0944 - accuracy: 0.9575\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1079 - accuracy: 0.9600\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.1629 - accuracy: 0.9550\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9725\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0855 - accuracy: 0.9750\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9775\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1967 - accuracy: 0.9275\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0849 - accuracy: 0.9750\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1333 - accuracy: 0.9400\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1233 - accuracy: 0.9650\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0563 - accuracy: 0.9800\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0935 - accuracy: 0.9775\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1172 - accuracy: 0.9475\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0946 - accuracy: 0.9700\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0894 - accuracy: 0.9675\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0731 - accuracy: 0.9775\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.1089 - accuracy: 0.9700\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0911 - accuracy: 0.9775\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0740 - accuracy: 0.9700\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9750\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9725\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9750\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0705 - accuracy: 0.9775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9832b3e050>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9tiN8kZA7_j",
        "outputId": "8be98cbe-eae3-441d-f55c-e627c74a2c44"
      },
      "source": [
        "# view model summary\n",
        "model.model.summary()\n",
        "\n",
        "# save model\n",
        "model.model.save(\n",
        "    F\"/content/gdrive/My Drive/Colab Notebooks/overall_key_classifier.h5\")\n",
        "# model.model.save(\"model/key_classifier.h5\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_30 (LSTM)              (None, 1, 128)            81920     \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 1, 128)            0         \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 1, 128)           512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_31 (LSTM)              (None, 1, 128)            131584    \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 1, 128)            0         \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 1, 128)           512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_32 (LSTM)              (None, 1, 64)             49408     \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 1, 64)             0         \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 1, 64)            256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 264,517\n",
            "Trainable params: 263,877\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhJoePB1kCC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12a9676-ded9-4034-d931-e870ea5aeb42"
      },
      "source": [
        "# load model for Google Drive\n",
        "model.model = load_model(\"/content/gdrive/My Drive/Colab Notebooks/overall_key_classifier.h5\")\n",
        "# model.model = load_model(\"model/key_classifier.h5\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = to_categorical(y_pred)\n",
        "\n",
        "# evaluate predictions\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy: %.3f%%\" % (acc*100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "GsAQPK5Lw-vm",
        "outputId": "f39fb649-244b-46fb-8429-e17552a14503"
      },
      "source": [
        "# import unseen data to check if model works\n",
        "pred_df = pd.read_csv(TEST_DATA_LINK)\n",
        "pred_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>sessionIndex</th>\n",
              "      <th>rep</th>\n",
              "      <th>H.period</th>\n",
              "      <th>DD.period.t</th>\n",
              "      <th>UD.period.t</th>\n",
              "      <th>H.t</th>\n",
              "      <th>DD.t.i</th>\n",
              "      <th>UD.t.i</th>\n",
              "      <th>H.i</th>\n",
              "      <th>DD.i.e</th>\n",
              "      <th>UD.i.e</th>\n",
              "      <th>H.e</th>\n",
              "      <th>DD.e.five</th>\n",
              "      <th>UD.e.five</th>\n",
              "      <th>H.five</th>\n",
              "      <th>DD.five.Shift.r</th>\n",
              "      <th>UD.five.Shift.r</th>\n",
              "      <th>H.Shift.r</th>\n",
              "      <th>DD.Shift.r.o</th>\n",
              "      <th>UD.Shift.r.o</th>\n",
              "      <th>H.o</th>\n",
              "      <th>DD.o.a</th>\n",
              "      <th>UD.o.a</th>\n",
              "      <th>H.a</th>\n",
              "      <th>DD.a.n</th>\n",
              "      <th>UD.a.n</th>\n",
              "      <th>H.n</th>\n",
              "      <th>DD.n.l</th>\n",
              "      <th>UD.n.l</th>\n",
              "      <th>H.l</th>\n",
              "      <th>DD.l.Return</th>\n",
              "      <th>UD.l.Return</th>\n",
              "      <th>H.Return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.174239</td>\n",
              "      <td>0.409866</td>\n",
              "      <td>0.235627</td>\n",
              "      <td>0.133840</td>\n",
              "      <td>0.171659</td>\n",
              "      <td>0.037820</td>\n",
              "      <td>0.156984</td>\n",
              "      <td>0.120599</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.111543</td>\n",
              "      <td>0.390015</td>\n",
              "      <td>0.278472</td>\n",
              "      <td>0.134937</td>\n",
              "      <td>0.264941</td>\n",
              "      <td>0.130004</td>\n",
              "      <td>0.144750</td>\n",
              "      <td>0.115824</td>\n",
              "      <td>-0.028925</td>\n",
              "      <td>0.120440</td>\n",
              "      <td>0.104092</td>\n",
              "      <td>-0.016348</td>\n",
              "      <td>0.137544</td>\n",
              "      <td>0.091721</td>\n",
              "      <td>-0.045824</td>\n",
              "      <td>0.099726</td>\n",
              "      <td>0.099142</td>\n",
              "      <td>-0.000585</td>\n",
              "      <td>0.120912</td>\n",
              "      <td>0.135934</td>\n",
              "      <td>0.015022</td>\n",
              "      <td>0.163508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.145289</td>\n",
              "      <td>0.154851</td>\n",
              "      <td>0.009562</td>\n",
              "      <td>0.131217</td>\n",
              "      <td>0.129134</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>0.130980</td>\n",
              "      <td>0.092216</td>\n",
              "      <td>-0.038764</td>\n",
              "      <td>0.118131</td>\n",
              "      <td>0.191068</td>\n",
              "      <td>0.072937</td>\n",
              "      <td>0.164665</td>\n",
              "      <td>0.306797</td>\n",
              "      <td>0.142132</td>\n",
              "      <td>0.145192</td>\n",
              "      <td>0.127395</td>\n",
              "      <td>-0.017797</td>\n",
              "      <td>0.132026</td>\n",
              "      <td>0.117957</td>\n",
              "      <td>-0.014069</td>\n",
              "      <td>0.164865</td>\n",
              "      <td>0.111584</td>\n",
              "      <td>-0.053281</td>\n",
              "      <td>0.101935</td>\n",
              "      <td>0.023678</td>\n",
              "      <td>-0.078258</td>\n",
              "      <td>0.140863</td>\n",
              "      <td>0.192325</td>\n",
              "      <td>0.051462</td>\n",
              "      <td>0.156958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.122266</td>\n",
              "      <td>0.136321</td>\n",
              "      <td>0.014055</td>\n",
              "      <td>0.114905</td>\n",
              "      <td>0.125308</td>\n",
              "      <td>0.010402</td>\n",
              "      <td>0.144332</td>\n",
              "      <td>0.098220</td>\n",
              "      <td>-0.046112</td>\n",
              "      <td>0.112351</td>\n",
              "      <td>0.198390</td>\n",
              "      <td>0.086040</td>\n",
              "      <td>0.121758</td>\n",
              "      <td>0.229243</td>\n",
              "      <td>0.107485</td>\n",
              "      <td>0.142623</td>\n",
              "      <td>0.143437</td>\n",
              "      <td>0.000814</td>\n",
              "      <td>0.120015</td>\n",
              "      <td>0.097180</td>\n",
              "      <td>-0.022835</td>\n",
              "      <td>0.145501</td>\n",
              "      <td>0.095982</td>\n",
              "      <td>-0.049520</td>\n",
              "      <td>0.121049</td>\n",
              "      <td>0.091486</td>\n",
              "      <td>-0.029563</td>\n",
              "      <td>0.111422</td>\n",
              "      <td>0.145751</td>\n",
              "      <td>0.034329</td>\n",
              "      <td>0.169304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.121075</td>\n",
              "      <td>0.132562</td>\n",
              "      <td>0.011487</td>\n",
              "      <td>0.134813</td>\n",
              "      <td>0.132049</td>\n",
              "      <td>-0.002763</td>\n",
              "      <td>0.135681</td>\n",
              "      <td>0.079597</td>\n",
              "      <td>-0.056084</td>\n",
              "      <td>0.102607</td>\n",
              "      <td>0.203487</td>\n",
              "      <td>0.100880</td>\n",
              "      <td>0.117718</td>\n",
              "      <td>0.227770</td>\n",
              "      <td>0.110051</td>\n",
              "      <td>0.170992</td>\n",
              "      <td>0.183585</td>\n",
              "      <td>0.012593</td>\n",
              "      <td>0.120631</td>\n",
              "      <td>0.127893</td>\n",
              "      <td>0.007262</td>\n",
              "      <td>0.135072</td>\n",
              "      <td>0.089715</td>\n",
              "      <td>-0.045356</td>\n",
              "      <td>0.117885</td>\n",
              "      <td>0.089209</td>\n",
              "      <td>-0.028676</td>\n",
              "      <td>0.098095</td>\n",
              "      <td>0.139069</td>\n",
              "      <td>0.040974</td>\n",
              "      <td>0.168298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Andy</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.141361</td>\n",
              "      <td>0.124721</td>\n",
              "      <td>-0.016640</td>\n",
              "      <td>0.098268</td>\n",
              "      <td>0.149003</td>\n",
              "      <td>0.050735</td>\n",
              "      <td>0.128713</td>\n",
              "      <td>0.102436</td>\n",
              "      <td>-0.026277</td>\n",
              "      <td>0.101371</td>\n",
              "      <td>0.220777</td>\n",
              "      <td>0.119406</td>\n",
              "      <td>0.112454</td>\n",
              "      <td>0.242917</td>\n",
              "      <td>0.130463</td>\n",
              "      <td>0.144625</td>\n",
              "      <td>0.142355</td>\n",
              "      <td>-0.002269</td>\n",
              "      <td>0.120052</td>\n",
              "      <td>0.152262</td>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.121480</td>\n",
              "      <td>0.078897</td>\n",
              "      <td>-0.042583</td>\n",
              "      <td>0.108607</td>\n",
              "      <td>0.049435</td>\n",
              "      <td>-0.059172</td>\n",
              "      <td>0.131348</td>\n",
              "      <td>0.156398</td>\n",
              "      <td>0.025050</td>\n",
              "      <td>0.170112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subject  sessionIndex  rep  ...  DD.l.Return  UD.l.Return  H.Return\n",
              "0    Andy             1    1  ...     0.135934     0.015022  0.163508\n",
              "1    Andy             1    2  ...     0.192325     0.051462  0.156958\n",
              "2    Andy             1    3  ...     0.145751     0.034329  0.169304\n",
              "3    Andy             1    4  ...     0.139069     0.040974  0.168298\n",
              "4    Andy             1    5  ...     0.156398     0.025050  0.170112\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no99ee2sVZvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fe826c-fab7-49ab-e570-dbec2cb9d857"
      },
      "source": [
        "pred_dataset = pred_df.values\n",
        "\n",
        "# divide data into features X\n",
        "# X_new = new_dataset[:,3:].astype(float)\n",
        "\n",
        "pred_row=pred_df.iloc[:,3:]\n",
        "# print(\"check name\")\n",
        "print(pred_df.iloc[0:7,0:1])\n",
        "\n",
        "# convert to\n",
        "pred_row = pred_row.values.tolist()\n",
        "pred_row = scaler.transform(pred_row)\n",
        "pred_arr = np.asarray(pred_row, dtype=np.float32)\n",
        "pred_arr = np.reshape(pred_arr, (pred_row.shape[0], TIMESTEPS, pred_arr.shape[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  subject\n",
            "0    Andy\n",
            "1    Andy\n",
            "2    Andy\n",
            "3    Andy\n",
            "4    Andy\n",
            "5   Azfar\n",
            "6   Azfar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZF7p6lFVZxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0c2c5d-1172-4e44-9bb7-2a932322c08d"
      },
      "source": [
        "# get prediction and its label\n",
        "pred = model.predict(pred_arr)\n",
        "pred = to_categorical(pred)\n",
        "pred = encoder.inverse_transform(pred)\n",
        "\n",
        "pred = np.squeeze(pred)\n",
        "\n",
        "pred_proba = model.predict_proba(pred_arr)\n",
        "acc = np.max(pred_proba, axis=1)\n",
        "\n",
        "print(pred)\n",
        "print(acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Andy' 'Andy' 'Andy' 'Andy' 'Andy' 'Azfar' 'Azfar' 'Azfar' 'Azfar'\n",
            " 'Azfar' 'Chris' 'Chris' 'Chris' 'Chris' 'Chris' 'Qikai' 'Qikai' 'Qikai'\n",
            " 'Qikai' 'Qikai' 'Safaraz' 'Safaraz' 'Safaraz' 'Safaraz' 'Safaraz']\n",
            "[0.9970372  0.99690634 0.99678135 0.99585354 0.9443761  0.9997373\n",
            " 0.99990714 0.9997161  0.9998529  0.99986684 0.9141486  0.999801\n",
            " 0.9993192  0.9994541  0.9957432  0.9997023  0.99755496 0.99392444\n",
            " 0.9996562  0.99647576 0.99814725 0.99881077 0.99283665 0.97376597\n",
            " 0.9313083 ]\n"
          ]
        }
      ]
    }
  ]
}